---
layout: post
title: Week 1, June 1 to June 7
---

## Week 1 ##
### June 1 2021 ###

Introduction to the members of the graduate program at the AABL. I talked to Dr. Short about potential research ideas. I was advised to talk to other graduate students to get more of an idea what I want to focus on for my research. I was advised to learn Machine Learning, Python, some of the Python Libraries and [ROS](http://wiki.ros.org/ROS/Tutorials) before I get started.

#### Some of the Python Libraries used for research in AI and ML: ####
* [Numpy](https://numpy.org/learn/)
* [SciPy](https://www.scipy.org/)
* [SciKit](https://scikit-learn.org/stable/)
* [PyTorch](https://pytorch.org/)

### June 2 2021 ###
I started learning [Machine Learning](https://www.coursera.org/learn/machine-learning/home). I meet up with Issac(PhD student at Tufts University) to learn more about their project and learned the three type of learning robots can do.

#### 1.Inverse Reinforcement Learning: ####
  * The researcher guides the robot to do a certain task.
  * A researcher might physically guide the robot arm to com-plete a certain task.
 
#### 2.Preference Learning: ####
  * A robot has to complete a task. However, it is given options to complete the task.
  * This gives the robot more freedom to be able to make a choice.
 
#### 3.Reinforcement Learning: ####
  * A robot is rewarded for doing a task correctly.
  * The robot is told it done a task correct or wrong.
  * This is the most popular type of learning for Machine Learning.

Issac research focuses on using reinforcement learning to speed up the time a robot is able to learn a task trhough human help/feedback.

### June 3 2021 ###

Today I meet up with Hang(PhD student at Tufts University) and Jindan(PhD student at Tufts University) to learn more about their research. Hang research pertains to learning how to avoid binary feedback, which is giving the feedback of wrong and correct to a robot, and instead use constructive feedbacks. An example would be

_When a robot does a task wrong instead of giving the binary feedback of "you did the task wrong". You give a reason to the robot on what it did wrong and how to improve on it._

Another focus Hang tries to solve is how to see how to long it takes for a robot to compelete a percenage of the task. Then looking at the time how to make the robot more efficent in compeleting the task.  

Jindan research focuses on tracking the behavior of humans interacting with robots. Then how to take the feedback from human to put into the robot. There are many ways human can show reaction to approval and disapproval and want to emulate it to the robot. I have looked at [DeepLizard](https://deeplizard.com/learn/video/nyjbcRQ-uQ8) to learn more about Reinforcement Learning. 

### June 4 2021 ###

Tufts University AALB has hacking hours every friday and I attended one for an hour. We workd on adding more information to the AALB google drive. During this time I have finished the first week of Machine Learning from Stanford University course. 

### June 7 2021 ###

Downloaded all of the python libraries needed for research. Also did some review of Python. That is the end of my first week at Tufts University!
